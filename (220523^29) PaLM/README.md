# PaLM: Scaling Language Modeling with Pathways (리뷰)
Google에서 공개한 540B 초거대 언어 모델. 수천 개의 TPU 칩에서 모델을 학습시키는 Pathways ML System을 활용한, 효율적인 LM의 Scaling-Up 학습 방법론을 제시함. Big-Bench를 비롯한 다양한 Benchmark에서 SOTA의 성능을 보이며, Reasoning Tasks에서 Chain-of-Thought이라는 Inference 방법론을 적용하여 좋은 성능을 도출함.<br/><br/>
References:
* [PaLM](https://arxiv.org/abs/2204.02311)
* [GPipe](https://arxiv.org/abs/1811.06965)
* [Parallel Training](https://lilianweng.github.io/posts/2021-09-25-train-large/)

간단한 [Review](https://chainsmokers.oopy.io/diary/palm)

